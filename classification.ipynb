{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chen-\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    686\n",
      "0    373\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('labelled_tweets.csv')\n",
    "\n",
    "df = df[df['Score'] != 2].reset_index(drop=True)\n",
    "print(df['Score'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chen-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# very basic text preprocessing\n",
    "def preprocess_tweets(raw_tweet):\n",
    "    # lowercase\n",
    "    raw_tweet = raw_tweet.lower()\n",
    "\n",
    "    # remove punctuation\n",
    "    raw_tweet = ''.join([c for c in raw_tweet if c not in string.punctuation])\n",
    "\n",
    "    # remove stopwords and apply stemming\n",
    "    raw_tweet = ' '.join([ps.stem(w) for w in raw_tweet.split() if w not in stop_words])\n",
    "\n",
    "    return raw_tweet\n",
    "\n",
    "\n",
    "df[\"preprocessed_tweet\"] = df[\"Cleaned Tweet\"].apply(preprocess_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\chen-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Cleaned Tweet</th>\n",
       "      <th>preprocessed_tweet</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Most people say when DXY peaks, the bottom wil...</td>\n",
       "      <td>peopl say dxi peak bottom well octob 2000 dxi ...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I stopped trading stocks Im now day/swing trad...</td>\n",
       "      <td>stop trade stock im daysw trade nasdaq amp swi...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sri Lanka's government officials from the fina...</td>\n",
       "      <td>sri lanka govern offici financ ministri centra...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>And the Dow Jones goes up about 900 points as ...</td>\n",
       "      <td>dow jone goe 900 point result mayb sport gambl...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Highest Outflow - 10/12/22 $SKLZ - 98% BEARISH...</td>\n",
       "      <td>highest outflow 101222 sklz 98 bearish ko 90 b...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                      Cleaned Tweet  \\\n",
       "0      1  Most people say when DXY peaks, the bottom wil...   \n",
       "1      1  I stopped trading stocks Im now day/swing trad...   \n",
       "2      1  Sri Lanka's government officials from the fina...   \n",
       "3      1  And the Dow Jones goes up about 900 points as ...   \n",
       "4      0  Highest Outflow - 10/12/22 $SKLZ - 98% BEARISH...   \n",
       "\n",
       "                                  preprocessed_tweet    neg    neu    pos  \\\n",
       "0  peopl say dxi peak bottom well octob 2000 dxi ...  0.046  0.825  0.129   \n",
       "1  stop trade stock im daysw trade nasdaq amp swi...  0.053  0.788  0.160   \n",
       "2  sri lanka govern offici financ ministri centra...  0.000  1.000  0.000   \n",
       "3  dow jone goe 900 point result mayb sport gambl...  0.000  0.791  0.209   \n",
       "4  highest outflow 101222 sklz 98 bearish ko 90 b...  0.000  1.000  0.000   \n",
       "\n",
       "   compound  \n",
       "0    0.3612  \n",
       "1    0.6705  \n",
       "2    0.0000  \n",
       "3    0.4404  \n",
       "4    0.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VADER (pretrained sentiment analyzer)\n",
    "nltk.download('vader_lexicon')\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through the headlines and get the polarity scores using vader\n",
    "scores = df['preprocessed_tweet'].apply(vader.polarity_scores).tolist()\n",
    "\n",
    "# Convert the 'scores' list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Join the DataFrames of the news and the list of dicts\n",
    "df_vader = df.join(scores_df, rsuffix='_right')\n",
    "df_vader.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 212\n"
     ]
    }
   ],
   "source": [
    "X, y = df.drop(columns=['Score']), df['Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the preprocessed strings\n",
    "cv = CountVectorizer(max_features=500)\n",
    "cv.fit(X_train[\"preprocessed_tweet\"].to_numpy())\n",
    "\n",
    "X_train = cv.transform(X_train[\"preprocessed_tweet\"].to_numpy()).toarray()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = cv.transform(X_test[\"preprocessed_tweet\"].to_numpy()).toarray()\n",
    "y_test = y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another vectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.75\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        80\n",
      "           1       0.83      0.76      0.79       132\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.74      0.75      0.74       212\n",
      "weighted avg       0.76      0.75      0.75       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.6981132075471698\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61        80\n",
      "           1       0.77      0.74      0.75       132\n",
      "\n",
      "    accuracy                           0.70       212\n",
      "   macro avg       0.68      0.68      0.68       212\n",
      "weighted avg       0.70      0.70      0.70       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.7028301886792453\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65        80\n",
      "           1       0.81      0.68      0.74       132\n",
      "\n",
      "    accuracy                           0.70       212\n",
      "   macro avg       0.70      0.71      0.70       212\n",
      "weighted avg       0.73      0.70      0.71       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.7688679245283019\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67        80\n",
      "           1       0.79      0.86      0.82       132\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.76      0.74      0.75       212\n",
      "weighted avg       0.77      0.77      0.76       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.6886792452830188\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.76      0.65        80\n",
      "           1       0.82      0.64      0.72       132\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.69      0.70      0.68       212\n",
      "weighted avg       0.72      0.69      0.69       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.7405660377358491\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.45      0.57        80\n",
      "           1       0.73      0.92      0.81       132\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.75      0.68      0.69       212\n",
      "weighted avg       0.75      0.74      0.72       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.7971698113207547\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70        80\n",
      "           1       0.80      0.89      0.85       132\n",
      "\n",
      "    accuracy                           0.80       212\n",
      "   macro avg       0.79      0.77      0.77       212\n",
      "weighted avg       0.80      0.80      0.79       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.7075471698113207\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        80\n",
      "           1       0.77      0.77      0.77       132\n",
      "\n",
      "    accuracy                           0.71       212\n",
      "   macro avg       0.69      0.69      0.69       212\n",
      "weighted avg       0.71      0.71      0.71       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.675287\n",
      "GradientBoostingClassifier    0.742631\n",
      "KNeighborsClassifier          0.676457\n",
      "LinearSVC                     0.716554\n",
      "LogisticRegression            0.752029\n",
      "MultinomialNB                 0.715433\n",
      "RandomForestClassifier        0.731939\n",
      "XGBClassifier                 0.735482\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.794118\n",
      "1       RandomForestClassifier         1  0.717647\n",
      "2       RandomForestClassifier         2  0.692308\n",
      "3       RandomForestClassifier         3  0.745562\n",
      "4       RandomForestClassifier         4  0.710059\n",
      "5                    LinearSVC         0  0.735294\n",
      "6                    LinearSVC         1  0.776471\n",
      "7                    LinearSVC         2  0.680473\n",
      "8                    LinearSVC         3  0.751479\n",
      "9                    LinearSVC         4  0.639053\n",
      "10               MultinomialNB         0  0.711765\n",
      "11               MultinomialNB         1  0.747059\n",
      "12               MultinomialNB         2  0.727811\n",
      "13               MultinomialNB         3  0.710059\n",
      "14               MultinomialNB         4  0.680473\n",
      "15          LogisticRegression         0  0.776471\n",
      "16          LogisticRegression         1  0.758824\n",
      "17          LogisticRegression         2  0.727811\n",
      "18          LogisticRegression         3  0.781065\n",
      "19          LogisticRegression         4  0.715976\n",
      "20      DecisionTreeClassifier         0  0.723529\n",
      "21      DecisionTreeClassifier         1  0.658824\n",
      "22      DecisionTreeClassifier         2  0.662722\n",
      "23      DecisionTreeClassifier         3  0.680473\n",
      "24      DecisionTreeClassifier         4  0.650888\n",
      "25  GradientBoostingClassifier         0  0.723529\n",
      "26  GradientBoostingClassifier         1  0.752941\n",
      "27  GradientBoostingClassifier         2  0.763314\n",
      "28  GradientBoostingClassifier         3  0.769231\n",
      "29  GradientBoostingClassifier         4  0.704142\n",
      "30               XGBClassifier         0  0.782353\n",
      "31               XGBClassifier         1  0.735294\n",
      "32               XGBClassifier         2  0.727811\n",
      "33               XGBClassifier         3  0.745562\n",
      "34               XGBClassifier         4  0.686391\n",
      "35        KNeighborsClassifier         0  0.735294\n",
      "36        KNeighborsClassifier         1  0.658824\n",
      "37        KNeighborsClassifier         2  0.662722\n",
      "38        KNeighborsClassifier         3  0.710059\n",
      "39        KNeighborsClassifier         4  0.615385\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    accuracies = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        80\n",
      "           1       0.79      0.83      0.81       132\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.74      0.74      0.74       212\n",
      "weighted avg       0.76      0.76      0.76       212\n",
      "\n",
      "Best Train Accuracy: 74.37% using {'subsample': 1, 'min_child_weight': 0, 'max_depth': 5, 'max_delta_step': 1, 'lambda': None, 'eta': 0.5, 'booster': 'dart'}\n",
      "Test Accuracy: 75.94%\n",
      "Accuracy of XGBClassifier: 0.7594\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "model_xgb_name = model_xgb.__class__.__name__\n",
    "\n",
    "boosters = ['gbtree', 'dart']\n",
    "learning_rates = [1, 0.5, 0.2, 0.1, 0.05, 0.01, 0, None]\n",
    "max_depths = [5, 20, 50, None]\n",
    "min_child_weights = [0, 5, 10, 50, None]\n",
    "max_delta_steps = list(range(10))\n",
    "subsamples = [0.5, 1]\n",
    "lambdas = [0, 5, 10, None]\n",
    "grid = {\n",
    "        'booster': boosters,\n",
    "        'eta': learning_rates,\n",
    "        'max_depth': max_depths,\n",
    "        'min_child_weight': min_child_weights,\n",
    "        'max_delta_step': max_delta_steps,\n",
    "        'subsample': subsamples,\n",
    "        'lambda': lambdas\n",
    "}\n",
    "\n",
    "classifier = RandomizedSearchCV(model_xgb, grid, scoring='accuracy', error_score=0, n_jobs=-1)\n",
    "grid_search = classifier.fit(X_train, y_train)\n",
    "y_train_pred = grid_search.predict(X_train)\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(f\"Classification Report of {model_xgb_name}:\\n{classification_report(y_test,y_test_pred)}\")\n",
    "print(f\"Best Train Accuracy: {grid_search.best_score_*100:.2f}% using {grid_search.best_params_}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred)*100:.2f}%\")\n",
    "print(f\"Accuracy of {model_xgb_name}: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c0c73153eda977619107ed9a86a029c7d43290595a37e5349af6ec2d36f67e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
