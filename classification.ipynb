{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chen-\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn import neural_network\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    686\n",
      "0    373\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('labelled_tweets.csv')\n",
    "\n",
    "df = df[df['Score'] != 2].reset_index(drop=True)\n",
    "print(df['Score'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('tweets_14031_20221017_232441.csv')\n",
    "df_labelled = pd.read_csv('labelled_tweets.csv')\n",
    "\n",
    "df_rem = pd.merge(\n",
    "    left=df_all, \n",
    "    right=df_labelled['Cleaned Tweet'],\n",
    "    how='left',\n",
    "    on=['Cleaned Tweet'],\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "df_rem = df_rem[df_rem['_merge'] == 'left_only'].reset_index(drop=True).drop(columns=['_merge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chen-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chen-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\chen-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# very basic text preprocessing\n",
    "def preprocess_tweets(raw_tweet):\n",
    "    # lowercase\n",
    "    raw_tweet = raw_tweet.lower()\n",
    "\n",
    "    # remove punctuation\n",
    "    raw_tweet = ''.join([c for c in raw_tweet if c not in string.punctuation])\n",
    "\n",
    "    # remove stopwords and apply stemming\n",
    "    # raw_tweet = ' '.join([ps.stem(w) for w in raw_tweet.split() if w not in stop_words])\n",
    "    raw_tweet = ' '.join([wnl.lemmatize(w) for w in raw_tweet.split() if w not in stop_words])\n",
    "\n",
    "    return raw_tweet\n",
    "\n",
    "\n",
    "df[\"preprocessed_tweet\"] = df[\"Cleaned Tweet\"].apply(preprocess_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\chen-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Cleaned Tweet</th>\n",
       "      <th>preprocessed_tweet</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Most people say when DXY peaks, the bottom wil...</td>\n",
       "      <td>people say dxy peak bottom well october 2000 d...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I stopped trading stocks Im now day/swing trad...</td>\n",
       "      <td>stopped trading stock im dayswing trading nasd...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sri Lanka's government officials from the fina...</td>\n",
       "      <td>sri lankas government official finance ministr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>And the Dow Jones goes up about 900 points as ...</td>\n",
       "      <td>dow jones go 900 point result maybe sport gamb...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Highest Outflow - 10/12/22 $SKLZ - 98% BEARISH...</td>\n",
       "      <td>highest outflow 101222 sklz 98 bearish ko 90 b...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                      Cleaned Tweet  \\\n",
       "0      1  Most people say when DXY peaks, the bottom wil...   \n",
       "1      1  I stopped trading stocks Im now day/swing trad...   \n",
       "2      1  Sri Lanka's government officials from the fina...   \n",
       "3      1  And the Dow Jones goes up about 900 points as ...   \n",
       "4      0  Highest Outflow - 10/12/22 $SKLZ - 98% BEARISH...   \n",
       "\n",
       "                                  preprocessed_tweet    neg    neu    pos  \\\n",
       "0  people say dxy peak bottom well october 2000 d...  0.046  0.825  0.129   \n",
       "1  stopped trading stock im dayswing trading nasd...  0.047  0.848  0.105   \n",
       "2  sri lankas government official finance ministr...  0.000  1.000  0.000   \n",
       "3  dow jones go 900 point result maybe sport gamb...  0.000  0.775  0.225   \n",
       "4  highest outflow 101222 sklz 98 bearish ko 90 b...  0.000  1.000  0.000   \n",
       "\n",
       "   compound  comp_score  \n",
       "0    0.3612           1  \n",
       "1    0.5106           1  \n",
       "2    0.0000           1  \n",
       "3    0.4927           1  \n",
       "4    0.0000           1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VADER (pretrained sentiment analyzer)\n",
    "nltk.download('vader_lexicon')\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through the headlines and get the polarity scores using vader\n",
    "scores = df['preprocessed_tweet'].apply(vader.polarity_scores).tolist()\n",
    "\n",
    "# Convert the 'scores' list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Join the DataFrames of the news and the list of dicts\n",
    "df_vader = df.join(scores_df, rsuffix='_right')\n",
    "\n",
    "# Anything more than > or equal to 0 is positive\n",
    "df_vader['comp_score'] = df_vader['compound'].apply(lambda c: 1 if c >= 0 else 0)\n",
    "\n",
    "df_vader.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader accuracy = 70.4438%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vader accuracy = {(df_vader['Score'] == df_vader['comp_score']).mean()*100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 212\n"
     ]
    }
   ],
   "source": [
    "X, y = df['preprocessed_tweet'].tolist(), df['Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "print(len(X_train), len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text vectorizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the preprocessed strings\n",
    "cv = CountVectorizer(max_features=500)\n",
    "\n",
    "X_CV = CountVectorizer().fit_transform(X)\n",
    "X_train_1 = cv.fit_transform(X_train)\n",
    "X_test_1 = cv.fit_transform(X_test)\n",
    "\n",
    "# Oversample count vectorizer\n",
    "X_train_1_O, y_train_1_O = SMOTE(random_state=1).fit_resample(X_train_1, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF\n",
    "X_train_tfidf = TfidfTransformer().fit_transform(X_train_1)\n",
    "X_test_tfidf = TfidfTransformer().fit_transform(X_test_1)\n",
    "\n",
    "# Oversample TFIDF\n",
    "X_train_tfidf_O = TfidfTransformer().fit_transform(X_train_1_O)\n",
    "y_train_tfidf_O = y_train_1_O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "X_train_BERT = model.encode(X_train)\n",
    "X_test_BERT = model.encode(X_test)\n",
    "\n",
    "X_train_BERT = MinMaxScaler().fit_transform(X_train_BERT)\n",
    "X_test_BERT = MinMaxScaler().fit_transform(X_test_BERT)\n",
    "\n",
    "#Oversample BERT\n",
    "X_train_BERT_O, y_train_BERT_O = SMOTE(random_state=1).fit_resample(X_train_BERT, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.5\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.56      0.46        80\n",
      "           1       0.64      0.46      0.54       132\n",
      "\n",
      "    accuracy                           0.50       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.54      0.50      0.51       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.6037735849056604\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.47        80\n",
      "           1       0.68      0.69      0.68       132\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.58      0.58      0.58       212\n",
      "weighted avg       0.60      0.60      0.60       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.5801886792452831\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.40      0.42        80\n",
      "           1       0.65      0.69      0.67       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.55      0.54      0.54       212\n",
      "weighted avg       0.57      0.58      0.58       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.6179245283018868\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.28      0.35        80\n",
      "           1       0.65      0.83      0.73       132\n",
      "\n",
      "    accuracy                           0.62       212\n",
      "   macro avg       0.57      0.55      0.54       212\n",
      "weighted avg       0.59      0.62      0.59       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.5188679245283019\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.68      0.51        80\n",
      "           1       0.68      0.42      0.52       132\n",
      "\n",
      "    accuracy                           0.52       212\n",
      "   macro avg       0.55      0.55      0.52       212\n",
      "weighted avg       0.58      0.52      0.52       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.6320754716981132\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.25      0.34        80\n",
      "           1       0.66      0.86      0.75       132\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.59      0.56      0.54       212\n",
      "weighted avg       0.61      0.63      0.59       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.5990566037735849\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.34      0.39        80\n",
      "           1       0.65      0.76      0.70       132\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.56      0.55      0.55       212\n",
      "weighted avg       0.58      0.60      0.58       212\n",
      "\n",
      "Accuracy of MLPClassifier:\t0.6320754716981132\n",
      "Classification Report of MLPClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.35      0.42        80\n",
      "           1       0.67      0.80      0.73       132\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.59      0.58      0.57       212\n",
      "weighted avg       0.61      0.63      0.61       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.5849056603773585\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.44        80\n",
      "           1       0.66      0.68      0.67       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.55      0.55      0.55       212\n",
      "weighted avg       0.58      0.58      0.58       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.683557\n",
      "GradientBoostingClassifier    0.717800\n",
      "KNeighborsClassifier          0.651660\n",
      "LinearSVC                     0.698844\n",
      "LogisticRegression            0.739025\n",
      "MLPClassifier                 0.713032\n",
      "MultinomialNB                 0.697689\n",
      "RandomForestClassifier        0.717793\n",
      "XGBClassifier                 0.711876\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.741176\n",
      "1       RandomForestClassifier         1  0.723529\n",
      "2       RandomForestClassifier         2  0.727811\n",
      "3       RandomForestClassifier         3  0.733728\n",
      "4       RandomForestClassifier         4  0.662722\n",
      "5                    LinearSVC         0  0.770588\n",
      "6                    LinearSVC         1  0.705882\n",
      "7                    LinearSVC         2  0.692308\n",
      "8                    LinearSVC         3  0.692308\n",
      "9                    LinearSVC         4  0.633136\n",
      "10               MultinomialNB         0  0.705882\n",
      "11               MultinomialNB         1  0.747059\n",
      "12               MultinomialNB         2  0.704142\n",
      "13               MultinomialNB         3  0.704142\n",
      "14               MultinomialNB         4  0.627219\n",
      "15          LogisticRegression         0  0.782353\n",
      "16          LogisticRegression         1  0.741176\n",
      "17          LogisticRegression         2  0.745562\n",
      "18          LogisticRegression         3  0.739645\n",
      "19          LogisticRegression         4  0.686391\n",
      "20      DecisionTreeClassifier         0  0.682353\n",
      "21      DecisionTreeClassifier         1  0.711765\n",
      "22      DecisionTreeClassifier         2  0.633136\n",
      "23      DecisionTreeClassifier         3  0.733728\n",
      "24      DecisionTreeClassifier         4  0.656805\n",
      "25  GradientBoostingClassifier         0  0.723529\n",
      "26  GradientBoostingClassifier         1  0.735294\n",
      "27  GradientBoostingClassifier         2  0.721893\n",
      "28  GradientBoostingClassifier         3  0.751479\n",
      "29  GradientBoostingClassifier         4  0.656805\n",
      "30               XGBClassifier         0  0.764706\n",
      "31               XGBClassifier         1  0.700000\n",
      "32               XGBClassifier         2  0.698225\n",
      "33               XGBClassifier         3  0.721893\n",
      "34               XGBClassifier         4  0.674556\n",
      "35               MLPClassifier         0  0.747059\n",
      "36               MLPClassifier         1  0.741176\n",
      "37               MLPClassifier         2  0.704142\n",
      "38               MLPClassifier         3  0.715976\n",
      "39               MLPClassifier         4  0.656805\n",
      "40        KNeighborsClassifier         0  0.688235\n",
      "41        KNeighborsClassifier         1  0.658824\n",
      "42        KNeighborsClassifier         2  0.644970\n",
      "43        KNeighborsClassifier         3  0.674556\n",
      "44        KNeighborsClassifier         4  0.591716\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    neural_network.MLPClassifier(random_state=0),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train_1, y_train)\n",
    "    pred = model.predict(X_test_1)\n",
    "    accuracies = cross_val_score(model, X_train_1, y_train, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.5707547169811321\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.42      0.43        80\n",
      "           1       0.65      0.66      0.66       132\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.54      0.54      0.54       212\n",
      "weighted avg       0.57      0.57      0.57       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.5754716981132075\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.62      0.53        80\n",
      "           1       0.71      0.55      0.62       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.58      0.59      0.57       212\n",
      "weighted avg       0.61      0.58      0.58       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.5754716981132075\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44        80\n",
      "           1       0.66      0.66      0.66       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.55      0.55      0.55       212\n",
      "weighted avg       0.58      0.58      0.58       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.589622641509434\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.56      0.51        80\n",
      "           1       0.70      0.61      0.65       132\n",
      "\n",
      "    accuracy                           0.59       212\n",
      "   macro avg       0.58      0.58      0.58       212\n",
      "weighted avg       0.61      0.59      0.60       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.5754716981132075\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.51      0.48        80\n",
      "           1       0.68      0.61      0.64       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.56      0.56      0.56       212\n",
      "weighted avg       0.59      0.58      0.58       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.49528301886792453\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.60      0.47        80\n",
      "           1       0.64      0.43      0.52       132\n",
      "\n",
      "    accuracy                           0.50       212\n",
      "   macro avg       0.52      0.52      0.49       212\n",
      "weighted avg       0.55      0.50      0.50       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.5566037735849056\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.40      0.41        80\n",
      "           1       0.64      0.65      0.65       132\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.53      0.53      0.53       212\n",
      "weighted avg       0.55      0.56      0.56       212\n",
      "\n",
      "Accuracy of MLPClassifier:\t0.6084905660377359\n",
      "Classification Report of MLPClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.46      0.47        80\n",
      "           1       0.68      0.70      0.69       132\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.58      0.58      0.58       212\n",
      "weighted avg       0.61      0.61      0.61       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.3867924528301887\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.97      0.55        80\n",
      "           1       0.67      0.03      0.06       132\n",
      "\n",
      "    accuracy                           0.39       212\n",
      "   macro avg       0.52      0.50      0.30       212\n",
      "weighted avg       0.56      0.39      0.24       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.759186\n",
      "GradientBoostingClassifier    0.751910\n",
      "KNeighborsClassifier          0.653443\n",
      "LinearSVC                     0.760055\n",
      "LogisticRegression            0.760939\n",
      "MLPClassifier                 0.776287\n",
      "MultinomialNB                 0.688557\n",
      "RandomForestClassifier        0.776369\n",
      "XGBClassifier                 0.785353\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.693694\n",
      "1       RandomForestClassifier         1  0.653153\n",
      "2       RandomForestClassifier         2  0.765766\n",
      "3       RandomForestClassifier         3  0.886878\n",
      "4       RandomForestClassifier         4  0.882353\n",
      "5                    LinearSVC         0  0.729730\n",
      "6                    LinearSVC         1  0.698198\n",
      "7                    LinearSVC         2  0.711712\n",
      "8                    LinearSVC         3  0.832579\n",
      "9                    LinearSVC         4  0.828054\n",
      "10               MultinomialNB         0  0.734234\n",
      "11               MultinomialNB         1  0.702703\n",
      "12               MultinomialNB         2  0.707207\n",
      "13               MultinomialNB         3  0.778281\n",
      "14               MultinomialNB         4  0.520362\n",
      "15          LogisticRegression         0  0.707207\n",
      "16          LogisticRegression         1  0.725225\n",
      "17          LogisticRegression         2  0.729730\n",
      "18          LogisticRegression         3  0.841629\n",
      "19          LogisticRegression         4  0.800905\n",
      "20      DecisionTreeClassifier         0  0.734234\n",
      "21      DecisionTreeClassifier         1  0.644144\n",
      "22      DecisionTreeClassifier         2  0.720721\n",
      "23      DecisionTreeClassifier         3  0.837104\n",
      "24      DecisionTreeClassifier         4  0.859729\n",
      "25  GradientBoostingClassifier         0  0.716216\n",
      "26  GradientBoostingClassifier         1  0.689189\n",
      "27  GradientBoostingClassifier         2  0.734234\n",
      "28  GradientBoostingClassifier         3  0.819005\n",
      "29  GradientBoostingClassifier         4  0.800905\n",
      "30               XGBClassifier         0  0.725225\n",
      "31               XGBClassifier         1  0.698198\n",
      "32               XGBClassifier         2  0.761261\n",
      "33               XGBClassifier         3  0.873303\n",
      "34               XGBClassifier         4  0.868778\n",
      "35               MLPClassifier         0  0.734234\n",
      "36               MLPClassifier         1  0.738739\n",
      "37               MLPClassifier         2  0.729730\n",
      "38               MLPClassifier         3  0.850679\n",
      "39               MLPClassifier         4  0.828054\n",
      "40        KNeighborsClassifier         0  0.653153\n",
      "41        KNeighborsClassifier         1  0.626126\n",
      "42        KNeighborsClassifier         2  0.666667\n",
      "43        KNeighborsClassifier         3  0.669683\n",
      "44        KNeighborsClassifier         4  0.651584\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    neural_network.MLPClassifier(random_state=0),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train_1_O, y_train_1_O)\n",
    "    pred = model.predict(X_test_1)\n",
    "    accuracies = cross_val_score(model, X_train_1_O, y_train_1_O, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.5660377358490566\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42        80\n",
      "           1       0.65      0.65      0.65       132\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.54      0.54      0.54       212\n",
      "weighted avg       0.57      0.57      0.57       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.6273584905660378\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.35      0.41        80\n",
      "           1       0.67      0.80      0.73       132\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.59      0.57      0.57       212\n",
      "weighted avg       0.61      0.63      0.61       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.6509433962264151\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.26      0.36        80\n",
      "           1       0.66      0.89      0.76       132\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.62      0.57      0.56       212\n",
      "weighted avg       0.63      0.65      0.61       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.660377358490566\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.16      0.27        80\n",
      "           1       0.65      0.96      0.78       132\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.69      0.56      0.52       212\n",
      "weighted avg       0.68      0.66      0.59       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.5094339622641509\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.69      0.51        80\n",
      "           1       0.68      0.40      0.50       132\n",
      "\n",
      "    accuracy                           0.51       212\n",
      "   macro avg       0.54      0.54      0.51       212\n",
      "weighted avg       0.58      0.51      0.51       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.6650943396226415\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.23      0.34        80\n",
      "           1       0.66      0.93      0.78       132\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.67      0.58      0.56       212\n",
      "weighted avg       0.67      0.67      0.61       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.6179245283018868\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.26      0.34        80\n",
      "           1       0.65      0.83      0.73       132\n",
      "\n",
      "    accuracy                           0.62       212\n",
      "   macro avg       0.57      0.55      0.54       212\n",
      "weighted avg       0.59      0.62      0.58       212\n",
      "\n",
      "Accuracy of MLPClassifier:\t0.6556603773584906\n",
      "Classification Report of MLPClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.40      0.47        80\n",
      "           1       0.69      0.81      0.75       132\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.63      0.61      0.61       212\n",
      "weighted avg       0.64      0.66      0.64       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.5613207547169812\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.47        80\n",
      "           1       0.67      0.58      0.62       132\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.55      0.55      0.55       212\n",
      "weighted avg       0.58      0.56      0.57       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.662332\n",
      "GradientBoostingClassifier    0.715454\n",
      "KNeighborsClassifier          0.677696\n",
      "LinearSVC                     0.734306\n",
      "LogisticRegression            0.740258\n",
      "MLPClassifier                 0.711883\n",
      "MultinomialNB                 0.721378\n",
      "RandomForestClassifier        0.708368\n",
      "XGBClassifier                 0.709558\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.700000\n",
      "1       RandomForestClassifier         1  0.729412\n",
      "2       RandomForestClassifier         2  0.715976\n",
      "3       RandomForestClassifier         3  0.710059\n",
      "4       RandomForestClassifier         4  0.686391\n",
      "5                    LinearSVC         0  0.776471\n",
      "6                    LinearSVC         1  0.735294\n",
      "7                    LinearSVC         2  0.727811\n",
      "8                    LinearSVC         3  0.757396\n",
      "9                    LinearSVC         4  0.674556\n",
      "10               MultinomialNB         0  0.741176\n",
      "11               MultinomialNB         1  0.694118\n",
      "12               MultinomialNB         2  0.751479\n",
      "13               MultinomialNB         3  0.715976\n",
      "14               MultinomialNB         4  0.704142\n",
      "15          LogisticRegression         0  0.735294\n",
      "16          LogisticRegression         1  0.747059\n",
      "17          LogisticRegression         2  0.763314\n",
      "18          LogisticRegression         3  0.745562\n",
      "19          LogisticRegression         4  0.710059\n",
      "20      DecisionTreeClassifier         0  0.670588\n",
      "21      DecisionTreeClassifier         1  0.658824\n",
      "22      DecisionTreeClassifier         2  0.656805\n",
      "23      DecisionTreeClassifier         3  0.650888\n",
      "24      DecisionTreeClassifier         4  0.674556\n",
      "25  GradientBoostingClassifier         0  0.723529\n",
      "26  GradientBoostingClassifier         1  0.717647\n",
      "27  GradientBoostingClassifier         2  0.733728\n",
      "28  GradientBoostingClassifier         3  0.704142\n",
      "29  GradientBoostingClassifier         4  0.698225\n",
      "30               XGBClassifier         0  0.711765\n",
      "31               XGBClassifier         1  0.711765\n",
      "32               XGBClassifier         2  0.698225\n",
      "33               XGBClassifier         3  0.721893\n",
      "34               XGBClassifier         4  0.704142\n",
      "35               MLPClassifier         0  0.752941\n",
      "36               MLPClassifier         1  0.705882\n",
      "37               MLPClassifier         2  0.727811\n",
      "38               MLPClassifier         3  0.698225\n",
      "39               MLPClassifier         4  0.674556\n",
      "40        KNeighborsClassifier         0  0.688235\n",
      "41        KNeighborsClassifier         1  0.658824\n",
      "42        KNeighborsClassifier         2  0.633136\n",
      "43        KNeighborsClassifier         3  0.715976\n",
      "44        KNeighborsClassifier         4  0.692308\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    neural_network.MLPClassifier(random_state=0),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    pred = model.predict(X_test_tfidf)\n",
    "    accuracies = cross_val_score(model, X_train_tfidf, y_train, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.5801886792452831\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.64      0.53        80\n",
      "           1       0.71      0.55      0.62       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.59      0.59      0.58       212\n",
      "weighted avg       0.62      0.58      0.59       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.6132075471698113\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51        80\n",
      "           1       0.70      0.66      0.68       132\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.60      0.60      0.60       212\n",
      "weighted avg       0.62      0.61      0.62       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.5518867924528302\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.46      0.44        80\n",
      "           1       0.65      0.61      0.63       132\n",
      "\n",
      "    accuracy                           0.55       212\n",
      "   macro avg       0.53      0.53      0.53       212\n",
      "weighted avg       0.56      0.55      0.56       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.5801886792452831\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.47        80\n",
      "           1       0.67      0.63      0.65       132\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.56      0.56      0.56       212\n",
      "weighted avg       0.59      0.58      0.58       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.5377358490566038\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45        80\n",
      "           1       0.65      0.56      0.60       132\n",
      "\n",
      "    accuracy                           0.54       212\n",
      "   macro avg       0.53      0.53      0.53       212\n",
      "weighted avg       0.56      0.54      0.54       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.49528301886792453\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.68      0.50        80\n",
      "           1       0.66      0.39      0.49       132\n",
      "\n",
      "    accuracy                           0.50       212\n",
      "   macro avg       0.53      0.53      0.50       212\n",
      "weighted avg       0.56      0.50      0.49       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.5471698113207547\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.75      0.56        80\n",
      "           1       0.74      0.42      0.54       132\n",
      "\n",
      "    accuracy                           0.55       212\n",
      "   macro avg       0.59      0.59      0.55       212\n",
      "weighted avg       0.63      0.55      0.54       212\n",
      "\n",
      "Accuracy of MLPClassifier:\t0.6273584905660378\n",
      "Classification Report of MLPClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        80\n",
      "           1       0.69      0.73      0.71       132\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.60      0.59      0.59       212\n",
      "weighted avg       0.62      0.63      0.62       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.37735849056603776\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55        80\n",
      "           1       0.00      0.00      0.00       132\n",
      "\n",
      "    accuracy                           0.38       212\n",
      "   macro avg       0.19      0.50      0.27       212\n",
      "weighted avg       0.14      0.38      0.21       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.738445\n",
      "GradientBoostingClassifier    0.749215\n",
      "KNeighborsClassifier          0.600167\n",
      "LinearSVC                     0.775350\n",
      "LogisticRegression            0.762741\n",
      "MLPClassifier                 0.766336\n",
      "MultinomialNB                 0.718332\n",
      "RandomForestClassifier        0.766410\n",
      "XGBClassifier                 0.751955\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.716216\n",
      "1       RandomForestClassifier         1  0.648649\n",
      "2       RandomForestClassifier         2  0.752252\n",
      "3       RandomForestClassifier         3  0.873303\n",
      "4       RandomForestClassifier         4  0.841629\n",
      "5                    LinearSVC         0  0.725225\n",
      "6                    LinearSVC         1  0.752252\n",
      "7                    LinearSVC         2  0.761261\n",
      "8                    LinearSVC         3  0.832579\n",
      "9                    LinearSVC         4  0.805430\n",
      "10               MultinomialNB         0  0.765766\n",
      "11               MultinomialNB         1  0.734234\n",
      "12               MultinomialNB         2  0.743243\n",
      "13               MultinomialNB         3  0.782805\n",
      "14               MultinomialNB         4  0.565611\n",
      "15          LogisticRegression         0  0.716216\n",
      "16          LogisticRegression         1  0.716216\n",
      "17          LogisticRegression         2  0.738739\n",
      "18          LogisticRegression         3  0.823529\n",
      "19          LogisticRegression         4  0.819005\n",
      "20      DecisionTreeClassifier         0  0.657658\n",
      "21      DecisionTreeClassifier         1  0.662162\n",
      "22      DecisionTreeClassifier         2  0.698198\n",
      "23      DecisionTreeClassifier         3  0.841629\n",
      "24      DecisionTreeClassifier         4  0.832579\n",
      "25  GradientBoostingClassifier         0  0.725225\n",
      "26  GradientBoostingClassifier         1  0.680180\n",
      "27  GradientBoostingClassifier         2  0.711712\n",
      "28  GradientBoostingClassifier         3  0.809955\n",
      "29  GradientBoostingClassifier         4  0.819005\n",
      "30               XGBClassifier         0  0.689189\n",
      "31               XGBClassifier         1  0.675676\n",
      "32               XGBClassifier         2  0.725225\n",
      "33               XGBClassifier         3  0.819005\n",
      "34               XGBClassifier         4  0.850679\n",
      "35               MLPClassifier         0  0.693694\n",
      "36               MLPClassifier         1  0.747748\n",
      "37               MLPClassifier         2  0.756757\n",
      "38               MLPClassifier         3  0.828054\n",
      "39               MLPClassifier         4  0.805430\n",
      "40        KNeighborsClassifier         0  0.617117\n",
      "41        KNeighborsClassifier         1  0.594595\n",
      "42        KNeighborsClassifier         2  0.603604\n",
      "43        KNeighborsClassifier         3  0.619910\n",
      "44        KNeighborsClassifier         4  0.565611\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    neural_network.MLPClassifier(random_state=0),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train_tfidf_O, y_train_tfidf_O)\n",
    "    pred = model.predict(X_test_tfidf)\n",
    "    accuracies = cross_val_score(model, X_train_tfidf_O, y_train_tfidf_O, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.7735849056603774\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.66        80\n",
      "           1       0.78      0.89      0.83       132\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.77      0.74      0.75       212\n",
      "weighted avg       0.77      0.77      0.77       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.6792452830188679\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56        80\n",
      "           1       0.73      0.77      0.75       132\n",
      "\n",
      "    accuracy                           0.68       212\n",
      "   macro avg       0.66      0.65      0.65       212\n",
      "weighted avg       0.67      0.68      0.68       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.7452830188679245\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.54      0.61        80\n",
      "           1       0.76      0.87      0.81       132\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.74      0.70      0.71       212\n",
      "weighted avg       0.74      0.75      0.74       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.7547169811320755\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.62        80\n",
      "           1       0.76      0.89      0.82       132\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.75      0.71      0.72       212\n",
      "weighted avg       0.75      0.75      0.74       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.6367924528301887\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.39      0.45        80\n",
      "           1       0.68      0.79      0.73       132\n",
      "\n",
      "    accuracy                           0.64       212\n",
      "   macro avg       0.60      0.59      0.59       212\n",
      "weighted avg       0.62      0.64      0.62       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.7594339622641509\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.65        80\n",
      "           1       0.78      0.86      0.82       132\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.75      0.73      0.73       212\n",
      "weighted avg       0.76      0.76      0.75       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.7641509433962265\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64        80\n",
      "           1       0.77      0.89      0.82       132\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.76      0.72      0.73       212\n",
      "weighted avg       0.76      0.76      0.76       212\n",
      "\n",
      "Accuracy of MLPClassifier:\t0.75\n",
      "Classification Report of MLPClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.45      0.58        80\n",
      "           1       0.74      0.93      0.82       132\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.77      0.69      0.70       212\n",
      "weighted avg       0.76      0.75      0.73       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.7594339622641509\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.54      0.63        80\n",
      "           1       0.76      0.89      0.82       132\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.76      0.72      0.73       212\n",
      "weighted avg       0.76      0.76      0.75       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.732043\n",
      "GradientBoostingClassifier    0.818204\n",
      "KNeighborsClassifier          0.809948\n",
      "LinearSVC                     0.799339\n",
      "LogisticRegression            0.807616\n",
      "MLPClassifier                 0.811166\n",
      "MultinomialNB                 0.801719\n",
      "RandomForestClassifier        0.814675\n",
      "XGBClassifier                 0.820571\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.800000\n",
      "1       RandomForestClassifier         1  0.800000\n",
      "2       RandomForestClassifier         2  0.822485\n",
      "3       RandomForestClassifier         3  0.857988\n",
      "4       RandomForestClassifier         4  0.792899\n",
      "5                    LinearSVC         0  0.764706\n",
      "6                    LinearSVC         1  0.794118\n",
      "7                    LinearSVC         2  0.798817\n",
      "8                    LinearSVC         3  0.852071\n",
      "9                    LinearSVC         4  0.786982\n",
      "10               MultinomialNB         0  0.776471\n",
      "11               MultinomialNB         1  0.770588\n",
      "12               MultinomialNB         2  0.828402\n",
      "13               MultinomialNB         3  0.863905\n",
      "14               MultinomialNB         4  0.769231\n",
      "15          LogisticRegression         0  0.782353\n",
      "16          LogisticRegression         1  0.782353\n",
      "17          LogisticRegression         2  0.822485\n",
      "18          LogisticRegression         3  0.852071\n",
      "19          LogisticRegression         4  0.798817\n",
      "20      DecisionTreeClassifier         0  0.729412\n",
      "21      DecisionTreeClassifier         1  0.694118\n",
      "22      DecisionTreeClassifier         2  0.757396\n",
      "23      DecisionTreeClassifier         3  0.781065\n",
      "24      DecisionTreeClassifier         4  0.698225\n",
      "25  GradientBoostingClassifier         0  0.805882\n",
      "26  GradientBoostingClassifier         1  0.811765\n",
      "27  GradientBoostingClassifier         2  0.816568\n",
      "28  GradientBoostingClassifier         3  0.881657\n",
      "29  GradientBoostingClassifier         4  0.775148\n",
      "30               XGBClassifier         0  0.805882\n",
      "31               XGBClassifier         1  0.811765\n",
      "32               XGBClassifier         2  0.857988\n",
      "33               XGBClassifier         3  0.869822\n",
      "34               XGBClassifier         4  0.757396\n",
      "35               MLPClassifier         0  0.758824\n",
      "36               MLPClassifier         1  0.805882\n",
      "37               MLPClassifier         2  0.834320\n",
      "38               MLPClassifier         3  0.869822\n",
      "39               MLPClassifier         4  0.786982\n",
      "40        KNeighborsClassifier         0  0.811765\n",
      "41        KNeighborsClassifier         1  0.782353\n",
      "42        KNeighborsClassifier         2  0.834320\n",
      "43        KNeighborsClassifier         3  0.840237\n",
      "44        KNeighborsClassifier         4  0.781065\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    neural_network.MLPClassifier(random_state=0),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train_BERT, y_train)\n",
    "    pred = model.predict(X_test_BERT)\n",
    "    accuracies = cross_val_score(model, X_train_BERT, y_train, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier:\t0.7877358490566038\n",
      "Classification Report of RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69        80\n",
      "           1       0.80      0.89      0.84       132\n",
      "\n",
      "    accuracy                           0.79       212\n",
      "   macro avg       0.78      0.76      0.76       212\n",
      "weighted avg       0.79      0.79      0.78       212\n",
      "\n",
      "Accuracy of LinearSVC:\t0.7122641509433962\n",
      "Classification Report of LinearSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.60        80\n",
      "           1       0.75      0.80      0.78       132\n",
      "\n",
      "    accuracy                           0.71       212\n",
      "   macro avg       0.69      0.68      0.69       212\n",
      "weighted avg       0.71      0.71      0.71       212\n",
      "\n",
      "Accuracy of MultinomialNB:\t0.7358490566037735\n",
      "Classification Report of MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.63        80\n",
      "           1       0.77      0.83      0.80       132\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.72      0.71      0.71       212\n",
      "weighted avg       0.73      0.74      0.73       212\n",
      "\n",
      "Accuracy of LogisticRegression:\t0.7735849056603774\n",
      "Classification Report of LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.66        80\n",
      "           1       0.78      0.89      0.83       132\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.77      0.74      0.75       212\n",
      "weighted avg       0.77      0.77      0.77       212\n",
      "\n",
      "Accuracy of DecisionTreeClassifier:\t0.6320754716981132\n",
      "Classification Report of DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.47        80\n",
      "           1       0.68      0.76      0.72       132\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.60      0.59      0.59       212\n",
      "weighted avg       0.62      0.63      0.62       212\n",
      "\n",
      "Accuracy of GradientBoostingClassifier:\t0.75\n",
      "Classification Report of GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.61        80\n",
      "           1       0.75      0.89      0.82       132\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.75      0.71      0.71       212\n",
      "weighted avg       0.75      0.75      0.74       212\n",
      "\n",
      "Accuracy of XGBClassifier:\t0.7594339622641509\n",
      "Classification Report of XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64        80\n",
      "           1       0.77      0.88      0.82       132\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.75      0.72      0.73       212\n",
      "weighted avg       0.76      0.76      0.75       212\n",
      "\n",
      "Accuracy of MLPClassifier:\t0.7641509433962265\n",
      "Classification Report of MLPClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.63        80\n",
      "           1       0.76      0.90      0.83       132\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.77      0.72      0.73       212\n",
      "weighted avg       0.76      0.76      0.75       212\n",
      "\n",
      "Accuracy of KNeighborsClassifier:\t0.7264150943396226\n",
      "Classification Report of KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69        80\n",
      "           1       0.86      0.67      0.75       132\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.73      0.75      0.72       212\n",
      "weighted avg       0.76      0.73      0.73       212\n",
      "\n",
      "Mean accuracies:\n",
      "model_name\n",
      "DecisionTreeClassifier        0.778044\n",
      "GradientBoostingClassifier    0.884518\n",
      "KNeighborsClassifier          0.796983\n",
      "LinearSVC                     0.875525\n",
      "LogisticRegression            0.875509\n",
      "MLPClassifier                 0.857478\n",
      "MultinomialNB                 0.778904\n",
      "RandomForestClassifier        0.893531\n",
      "XGBClassifier                 0.887224\n",
      "Name: accuracy, dtype: float64\n",
      "\n",
      "Full training table:\n",
      "                    model_name  fold_idx  accuracy\n",
      "0       RandomForestClassifier         0  0.842342\n",
      "1       RandomForestClassifier         1  0.914414\n",
      "2       RandomForestClassifier         2  0.891892\n",
      "3       RandomForestClassifier         3  0.918552\n",
      "4       RandomForestClassifier         4  0.900452\n",
      "5                    LinearSVC         0  0.801802\n",
      "6                    LinearSVC         1  0.873874\n",
      "7                    LinearSVC         2  0.869369\n",
      "8                    LinearSVC         3  0.914027\n",
      "9                    LinearSVC         4  0.918552\n",
      "10               MultinomialNB         0  0.743243\n",
      "11               MultinomialNB         1  0.783784\n",
      "12               MultinomialNB         2  0.783784\n",
      "13               MultinomialNB         3  0.787330\n",
      "14               MultinomialNB         4  0.796380\n",
      "15          LogisticRegression         0  0.815315\n",
      "16          LogisticRegression         1  0.869369\n",
      "17          LogisticRegression         2  0.878378\n",
      "18          LogisticRegression         3  0.914027\n",
      "19          LogisticRegression         4  0.900452\n",
      "20      DecisionTreeClassifier         0  0.756757\n",
      "21      DecisionTreeClassifier         1  0.752252\n",
      "22      DecisionTreeClassifier         2  0.752252\n",
      "23      DecisionTreeClassifier         3  0.832579\n",
      "24      DecisionTreeClassifier         4  0.796380\n",
      "25  GradientBoostingClassifier         0  0.846847\n",
      "26  GradientBoostingClassifier         1  0.878378\n",
      "27  GradientBoostingClassifier         2  0.882883\n",
      "28  GradientBoostingClassifier         3  0.914027\n",
      "29  GradientBoostingClassifier         4  0.900452\n",
      "30               XGBClassifier         0  0.846847\n",
      "31               XGBClassifier         1  0.878378\n",
      "32               XGBClassifier         2  0.891892\n",
      "33               XGBClassifier         3  0.932127\n",
      "34               XGBClassifier         4  0.886878\n",
      "35               MLPClassifier         0  0.801802\n",
      "36               MLPClassifier         1  0.864865\n",
      "37               MLPClassifier         2  0.819820\n",
      "38               MLPClassifier         3  0.909502\n",
      "39               MLPClassifier         4  0.891403\n",
      "40        KNeighborsClassifier         0  0.774775\n",
      "41        KNeighborsClassifier         1  0.765766\n",
      "42        KNeighborsClassifier         2  0.792793\n",
      "43        KNeighborsClassifier         3  0.823529\n",
      "44        KNeighborsClassifier         4  0.828054\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    neural_network.MLPClassifier(random_state=0),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_train_BERT_O, y_train_BERT_O)\n",
    "    pred = model.predict(X_test_BERT)\n",
    "    accuracies = cross_val_score(model, X_train_BERT_O, y_train_BERT_O, scoring='accuracy', cv=CV)\n",
    "\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "    print(f\"Accuracy of {model_name}:\\t{accuracy_score(y_test, pred)}\")\n",
    "    print(f\"Classification Report of {model_name}:\\n{classification_report(y_test, pred)}\")\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "print(f\"Mean accuracies:\\n{cv_df.groupby('model_name').accuracy.mean()}\\n\")\n",
    "print(f\"Full training table:\\n{cv_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of ensemble model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65        80\n",
      "           1       0.77      0.90      0.83       132\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.77      0.73      0.74       212\n",
      "weighted avg       0.77      0.77      0.76       212\n",
      "\n",
      "Accuracy of ensemble model: 0.7736\n"
     ]
    }
   ],
   "source": [
    "# exclude KNN, DT, MNB\n",
    "ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(random_state=0)),\n",
    "        ('lsvc', LinearSVC(random_state=0)),\n",
    "        ('log', LogisticRegression(random_state=0)),\n",
    "        ('gb', GradientBoostingClassifier(random_state=0)),\n",
    "        # ('xgb', xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)),\n",
    "        ('mlp', neural_network.MLPClassifier(random_state=0))\n",
    "    ],\n",
    "    final_estimator=None,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "ensemble = ensemble.fit(X_train_BERT_O, y_train_BERT_O)\n",
    "y_test_pred = ensemble.predict(X_test_BERT)\n",
    "\n",
    "print(f\"Classification Report of ensemble model:\\n{classification_report(y_test, y_test_pred)}\")\n",
    "print(f\"Accuracy of ensemble model: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ensemble, 'model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb = GradientBoostingClassifier(random_state=0)\n",
    "model_gb_name = model_gb.__class__.__name__\n",
    "n_estimators = [int(x) for x in np.linspace(start=50, stop=150, num=3)]\n",
    "learning_rate = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "max_depth = [5, 20, 50, None]\n",
    "min_samples_split = list(range(1, 16))\n",
    "min_samples_leaf = list(range(1, 16))\n",
    "max_features = ['auto', 'sqrt']\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features\n",
    "}\n",
    "\n",
    "classifier = RandomizedSearchCV(model_gb, grid, n_iter=50, scoring='accuracy', error_score=0, n_jobs=-1)\n",
    "grid_search = classifier.fit(X_train_BERT, y_train)\n",
    "y_train_pred = grid_search.predict(X_train_BERT)\n",
    "y_test_pred = grid_search.predict(X_test_BERT)\n",
    "\n",
    "print(f\"Classification Report of {model_gb_name}:\\n{classification_report(y_test, y_test_pred)}\")\n",
    "print(f\"Best Train Accuracy: {grid_search.best_score_*100:.2f}% using {grid_search.best_params_}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred)*100:.2f}%\")\n",
    "print(f\"Accuracy of {model_gb_name}: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "model_xgb_name = model_xgb.__class__.__name__\n",
    "\n",
    "boosters = ['gbtree', 'dart']\n",
    "learning_rates = [1, 0.5, 0.2, 0.1, 0.05, 0.01, 0, None]\n",
    "max_depths = [5, 20, 50, None]\n",
    "min_child_weights = [0, 5, 10, 50, None]\n",
    "max_delta_steps = list(range(10))\n",
    "subsamples = [0.5, 1]\n",
    "lambdas = [0, 5, 10, None]\n",
    "grid = {\n",
    "        'booster': boosters,\n",
    "        'eta': learning_rates,\n",
    "        'max_depth': max_depths,\n",
    "        'min_child_weight': min_child_weights,\n",
    "        'max_delta_step': max_delta_steps,\n",
    "        'subsample': subsamples,\n",
    "        'lambda': lambdas\n",
    "}\n",
    "\n",
    "classifier = RandomizedSearchCV(model_xgb, grid, n_iter=50, scoring='accuracy', error_score=0, n_jobs=-1)\n",
    "grid_search = classifier.fit(X_train_BERT, y_train)\n",
    "y_train_pred = grid_search.predict(X_train_BERT)\n",
    "y_test_pred = grid_search.predict(X_test_BERT)\n",
    "\n",
    "print(f\"Classification Report of {model_xgb_name}:\\n{classification_report(y_test, y_test_pred)}\")\n",
    "print(f\"Best Train Accuracy: {grid_search.best_score_*100:.2f}% using {grid_search.best_params_}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred)*100:.2f}%\")\n",
    "print(f\"Accuracy of {model_xgb_name}: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee9fd3a3fb935108ddb9ca82c651d0e2d224fcf33f117b667a015a7078326a00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
